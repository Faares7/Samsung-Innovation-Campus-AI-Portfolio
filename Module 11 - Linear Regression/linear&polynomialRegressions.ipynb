{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fares Ahmed Moustafa**\n",
        "### *F.ahmed2270@nu.edu.eg*"
      ],
      "metadata": {
        "id": "OEFoG3dfH2f5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Correlation:**\n",
        "Measures the linear relationship between two variables.\n",
        "\n",
        "It’s a statistic, usually expressed using values between -1 and +1.\n",
        "\n",
        "\n",
        "## **Multicollinearity:**\n",
        "\n",
        "Happens when two or more independent variables in a regression model are highly correlated with each other."
      ],
      "metadata": {
        "id": "7SXE8fp1H-iL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Types of Gradient Descent Algorithms**\n",
        "\n",
        "## **Batch Gradient Descent**\n",
        "\n",
        "Uses the entire dataset to compute gradients.\n",
        "\n",
        "**Advantages:** Stable convergence, accurate minimum.\n",
        "\n",
        "**Limitations:** Very slow on large datasets.\n",
        "\n",
        "\n",
        "\n",
        "## **Stochastic Gradient Descent (SGD)**\n",
        "\n",
        "Updates weights for each training sample (one at a time).\n",
        "\n",
        "**Advantages:** Fast, good for very large datasets, can escape local minima.\n",
        "\n",
        "**Limitations:** Very noisy, convergence fluctuates.\n",
        "\n",
        "\n",
        "\n",
        "## **Mini-Batch Gradient Descent**\n",
        "\n",
        "Compromise between Batch and SGD – updates using small subsets (batches).\n",
        "\n",
        "**Advantages:** Efficient, balances speed and stability, uses vectorization.\n",
        "\n",
        "**Limitations:** Still needs tuning of batch size.\n",
        "\n",
        "\n",
        "\n",
        "# **Types of Regularization**\n",
        "\n",
        "## **L1 Regularization (Lasso)**\n",
        "\n",
        "Forces some coefficients to 0 → performs feature selection.\n",
        "\n",
        "Good when many irrelevant features exist.\n",
        "\n",
        "Can be unstable if features are highly correlated.\n",
        "\n",
        "## **L2 Regularization (Ridge)**\n",
        "\n",
        "Shrinks coefficients but never sets them exactly to 0.\n",
        "\n",
        "Works well when predictors are correlated.\n",
        "\n",
        "Doesn’t eliminate irrelevant features.\n"
      ],
      "metadata": {
        "id": "zVqvIib0H-qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"train_energy_data.csv\")\n",
        "\n",
        "X = data.drop(\"Energy Consumption\", axis=1)\n",
        "y = data[\"Energy Consumption\"]\n",
        "\n",
        "categorical_features = [\"Building Type\", \"Day of Week\"]\n",
        "numerical_features = [\"Square Footage\", \"Number of Occupants\", \"Appliances Used\", \"Average Temperature\"]\n",
        "\n",
        "# Linear Regression\n",
        "linear_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
        "        (\"num\", \"passthrough\", numerical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "linear_model = Pipeline(steps=[\n",
        "    (\"preprocessor\", linear_preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "\n",
        "linear_model.fit(X, y)\n",
        "y_pred_lin = linear_model.predict(X)\n",
        "\n",
        "print(\"Linear Regression Results:\")\n",
        "print(\"MSE:\", mean_squared_error(y, y_pred_lin))\n",
        "print(\"R2 Score:\", r2_score(y, y_pred_lin))\n",
        "\n",
        "# Polynomial Regression (degree=2 as example)\n",
        "poly_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_features),\n",
        "        (\"num\", PolynomialFeatures(degree=2, include_bias=False), numerical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "poly_model = Pipeline(steps=[\n",
        "    (\"preprocessor\", poly_preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "\n",
        "poly_model.fit(X, y)\n",
        "y_pred_poly = poly_model.predict(X)\n",
        "\n",
        "print(\"\\nPolynomial Regression Results (degree=2):\")\n",
        "print(\"MSE:\", mean_squared_error(y, y_pred_poly))\n",
        "print(\"R2 Score:\", r2_score(y, y_pred_poly))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f33ttwx8H2mN",
        "outputId": "183923a5-d7ab-4f4a-a191-cffc403c7a1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Results:\n",
            "MSE: 0.0001863116596849601\n",
            "R2 Score: 0.9999999997858984\n",
            "\n",
            "Polynomial Regression Results (degree=2):\n",
            "MSE: 0.00018460644937261903\n",
            "R2 Score: 0.999999999787858\n"
          ]
        }
      ]
    }
  ]
}